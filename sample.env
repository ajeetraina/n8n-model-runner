# PostgreSQL Configuration
POSTGRES_DB=n8n
POSTGRES_USER=n8n
POSTGRES_PASSWORD=n8n_password_change_this

# n8n Configuration
N8N_HOST=localhost
N8N_PORT=5678
N8N_PROTOCOL=http
WEBHOOK_URL=http://localhost:5678/
GENERIC_TIMEZONE=America/New_York

# Security - CHANGE THIS TO A RANDOM STRING
N8N_ENCRYPTION_KEY=your-very-secure-encryption-key-change-this-to-random-string

# Docker Model Runner Configuration
N8N_AI_OPENAI_API_BASE=http://model-runner.docker.internal/engines/llama.cpp/v1
N8N_AI_OPENAI_API_KEY=local
N8N_AI_DEFAULT_MODEL=ai/llama3.2:1B-Q8_0

# Alternative TCP configuration (if you enable TCP host support)
# N8N_AI_OPENAI_API_BASE=http://host.docker.internal:12434/engines/llama.cpp/v1

# Queue Configuration (for production)
EXECUTIONS_MODE=queue
QUEUE_BULL_REDIS_HOST=redis
QUEUE_BULL_REDIS_PORT=6379

# Advanced Configuration
NODE_ENV=production
NODE_FUNCTION_ALLOW_BUILTIN=*
NODE_FUNCTION_ALLOW_EXTERNAL=*

# Available Models (reference - choose one for N8N_AI_DEFAULT_MODEL)
# ai/llama3.2:1B-Q8_0    # Lightweight, fast
# ai/llama3.2:3B         # Balanced performance
# ai/gemma3:2B           # Good for general tasks
# ai/qwen2.5:7B          # More capable, slower
# ai/mistral:7B          # Good for code and reasoning
